{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "915d8883"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYmEKXsNbw8z"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from src import preprocess_mnist\n",
        "from src import NNModel\n",
        "from src import train_model\n",
        "from src import plot_training_curves\n",
        "from src import detect_convergence, plot_convergence\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55322b37"
      },
      "source": [
        "## Displaying Non-Flattened MNIST Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "45TC_uUZeWWW",
        "outputId": "301e87c7-5941-4bca-ffa6-0f3c23b1b45a"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader = preprocess_mnist(flatten=False)\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "fig, axes = plt.subplots(1, 8, figsize=(12, 2))\n",
        "for i in range(8):\n",
        "    axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
        "    axes[i].set_title(str(labels[i].item()))\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecf7b623"
      },
      "source": [
        "## Displaying Flattened MNIST Data Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGv4bZFseQAV",
        "outputId": "15ff5b0a-1cfd-4ef5-dfc3-5beb63dc1c80"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader = preprocess_mnist(batch_size=64, augment=False, flatten=True)\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"Images batch shape: {images.shape}\")\n",
        "print(f\"Labels batch shape: {labels.shape}\")\n",
        "print(f\"Example labels: {labels[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model, loss, optimizer\n",
        "model = NNModel().to(device)\n",
        "model.apply(model._init_weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# Train\n",
        "history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs, device=device)\n",
        "\n",
        "# Plot\n",
        "plot_training_curves(history, epochs=epochs)\n",
        "conv_epoch = detect_convergence(history[\"val_loss_mean\"])\n",
        "plot_convergence(history[\"train_loss_mean\"], history[\"val_loss_mean\"], conv_epoch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Learning Rate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test values : [0.001, 0.01, 0.1, 1.0]\n",
        "learning_rates = [0.001, 0.01, 0.1, 1.0]\n",
        "epochs = 10\n",
        "results_lr = {}\n",
        "for lr in learning_rates:\n",
        "    print(f\"Training with learning rate: {lr}\")\n",
        "    model = NNModel().to(device)\n",
        "    model.apply(model._init_weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    result = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs, device=device)\n",
        "    results_lr[lr] = result\n",
        "    plot_training_curves(result, epochs=epochs)\n",
        "    conv_epoch = detect_convergence(result[\"val_loss_mean\"])\n",
        "    plot_convergence(result[\"train_loss_mean\"], result[\"val_loss_mean\"], conv_epoch)\n",
        "\n",
        "# best lr \n",
        "best_lr = None\n",
        "best_acc = 0.0\n",
        "\n",
        "for lr, history in results_lr.items():\n",
        "    val_acc = history[\"val_acc_mean\"][-1]\n",
        "    print(f\"LR {lr:<5} → Final Val Acc: {val_acc*100:.2f}%\")\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_lr = lr\n",
        "\n",
        "print(f\"\\nBest Learning Rate: {best_lr} with Val Acc = {best_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Batch Size Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Values : [16, 32, 64, 128]\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "epochs = 10\n",
        "results_bs = {} \n",
        "\n",
        "for bs in batch_sizes:  \n",
        "    print(f\"Training with batch size: {bs}\")\n",
        "    train_loader_bs, val_loader_bs, test_loader_bs = preprocess_mnist(batch_size=bs, augment=False, flatten=True)\n",
        "   \n",
        "    # model, loss, optimizer\n",
        "    model = NNModel().to(device)\n",
        "    model.apply(model._init_weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    \n",
        "    \n",
        "    result = train_model(model, train_loader_bs, val_loader_bs, criterion, optimizer, epochs=epochs, device=device)\n",
        "    results_bs[bs] = result\n",
        "\n",
        " \n",
        "# best batch size\n",
        "best_bs = None\n",
        "best_acc = 0.0  \n",
        "for bs, history in results_bs.items():\n",
        "    val_acc = history[\"val_acc_mean\"][-1]\n",
        "    print(f\"BS {bs:<5} → Final Val Acc: {val_acc*100:.2f}%\")\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_bs = bs\n",
        "\n",
        "print(f\"\\nBest Batch Size: {best_bs} with Val Acc = {best_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Architecture Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [2, 3, 4, 5]\n",
        "neurons_per_layer = [64, 128, 256, 512]\n",
        "epochs = 10\n",
        "results_arch = {}\n",
        "\n",
        "for num_layers in layers:\n",
        "    for neurons in neurons_per_layer:\n",
        "        print(f\"Training with {num_layers} layers and {neurons} neurons per layer\")\n",
        "\n",
        "        model = NNModel(hidden_sizes=[neurons]*num_layers).to(device)\n",
        "        model.apply(model._init_weights)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "        \n",
        "        result = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs, device=device)\n",
        "        results_arch[(num_layers, neurons)] = result\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
