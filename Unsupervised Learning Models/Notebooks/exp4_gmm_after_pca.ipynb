{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from utils.data import load_breast_cancer_kagglehub, standardize_fit_transform\n",
    "from utils.internal_metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_index,\n",
    "    calinski_harabasz_index,\n",
    "    wcss,\n",
    ")\n",
    "from utils.external_metrics import (\n",
    "    adjusted_rand_index,\n",
    "    normalized_mutual_info,\n",
    "    purity_score,\n",
    ")\n",
    "from GMM import GMM\n",
    "from PCA import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f409f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feature_names = load_breast_cancer_kagglehub()\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "print(\"Data shape:\", Xs.shape)\n",
    "\n",
    "# ------------------- PCA components -------------------\n",
    "components_list = [2, 5, 10, 15, 20]\n",
    "cov_types = ['full', 'tied', 'diag', 'spherical']\n",
    "seed = 42\n",
    "\n",
    "# Store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in components_list:\n",
    "    pca = PCA(n_components=m, random_state=seed)\n",
    "    Z = pca.fit_transform(Xs)\n",
    "    results[m] = {}\n",
    "\n",
    "    for cov in cov_types:\n",
    "        bic_list, aic_list, loglik_list, gmm_models = [], [], [], []\n",
    "\n",
    "        # Test GMM with k=2 clusters\n",
    "        gmm = GMM(n_components=2, covariance_type=cov, max_iter=200, random_state=seed)\n",
    "        gmm.fit(Z)\n",
    "\n",
    "        bic_list.append(gmm.bic(Z))\n",
    "        aic_list.append(gmm.aic(Z))\n",
    "        loglik_list.append(gmm.log_likelihoods_)\n",
    "        gmm_models.append(gmm)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = gmm.predict(Z)\n",
    "\n",
    "        # Internal metrics\n",
    "        sil = silhouette_score(Z, y_pred)\n",
    "        dbi = davies_bouldin_index(Z, y_pred)\n",
    "        ch = calinski_harabasz_index(Z, y_pred)\n",
    "        wcss_val = wcss(Z, y_pred, gmm.means_)\n",
    "\n",
    "        # External metrics\n",
    "        ari = adjusted_rand_index(y, y_pred)\n",
    "        nmi = normalized_mutual_info(y, y_pred)\n",
    "        pur = purity_score(y, y_pred)\n",
    "\n",
    "        # Store everything\n",
    "        results[m][cov] = {\n",
    "            'BIC': bic_list[0],\n",
    "            'AIC': aic_list[0],\n",
    "            'loglik': loglik_list[0],\n",
    "            'silhouette': sil,\n",
    "            'davies_bouldin': dbi,\n",
    "            'calinski_harabasz': ch,\n",
    "            'wcss': wcss_val,\n",
    "            'ARI': ari,\n",
    "            'NMI': nmi,\n",
    "            'Purity': pur,\n",
    "            'model': gmm\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a96871",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cov_per_dim = {}\n",
    "\n",
    "for m in components_list:\n",
    "    \n",
    "    # Collect ALL values for min/max per metric (across cov_types)\n",
    "    sil_vals = [results[m][cov][\"silhouette\"] for cov in cov_types]\n",
    "    ch_vals = [results[m][cov][\"calinski_harabasz\"] for cov in cov_types]\n",
    "    db_vals = [results[m][cov][\"davies_bouldin\"] for cov in cov_types]\n",
    "    loglik_vals = [results[m][cov][\"loglik\"][-1] for cov in cov_types]\n",
    "    bic_vals = [results[m][cov][\"BIC\"] for cov in cov_types]\n",
    "\n",
    "    # Min-max per metric\n",
    "    min_sil, max_sil = min(sil_vals), max(sil_vals)\n",
    "    min_ch, max_ch = min(ch_vals), max(ch_vals)\n",
    "    min_db, max_db = min(db_vals), max(db_vals)\n",
    "    min_loglik, max_loglik = min(loglik_vals), max(loglik_vals)\n",
    "    min_bic, max_bic = min(bic_vals), max(bic_vals)\n",
    "\n",
    "    denom_sil = max(max_sil - min_sil, 1e-8)\n",
    "    denom_ch = max(max_ch - min_ch, 1e-8)\n",
    "    denom_db = max(max_db - min_db, 1e-8)\n",
    "    denom_loglik = max(max_loglik - min_loglik, 1e-8)\n",
    "    denom_bic = max(max_bic - min_bic, 1e-8)\n",
    "\n",
    "    best_cov = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for cov in cov_types:\n",
    "        stats = results[m][cov]\n",
    "\n",
    "        # Normalize each to [0,1], higher = better\n",
    "        norm_sil = (stats[\"silhouette\"] - min_sil) / denom_sil\n",
    "        norm_ch = (stats[\"calinski_harabasz\"] - min_ch) / denom_ch\n",
    "        norm_db = (max_db - stats[\"davies_bouldin\"]) / denom_db  # Lower DBI better\n",
    "        norm_loglik = (stats[\"loglik\"][-1] - min_loglik) / denom_loglik\n",
    "        norm_bic = (max_bic - stats[\"BIC\"]) / denom_bic  # Lower BIC better\n",
    "\n",
    "        # Combined: sum (or np.mean([...]) for average)\n",
    "        combined_score = norm_sil + norm_ch + norm_db + norm_loglik + norm_bic\n",
    "\n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_cov = cov\n",
    "\n",
    "    best_cov_per_dim[m] = {\"best_covariance\": best_cov, \"combined_score\": best_score}\n",
    "\n",
    "\n",
    "# Prepare DataFrame\n",
    "df_best_cov = pd.DataFrame(best_cov_per_dim).T\n",
    "df_best_cov.index.name = \"PCA_components\"\n",
    "\n",
    "# Round values for better display\n",
    "df_best_cov = df_best_cov.round(4)\n",
    "print(tabulate(df_best_cov.reset_index(), headers='keys', tablefmt='fancy_grid', showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4874ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for m in components_list:\n",
    "    for cov in cov_types:\n",
    "        stats = results[m][cov]\n",
    "        rows.append({\n",
    "            'PCA_components': m,\n",
    "            'Covariance': cov,\n",
    "            'silhouette': stats['silhouette'],\n",
    "            'davies_bouldin': stats['davies_bouldin'],\n",
    "            'BIC': stats['BIC'],\n",
    "            'ARI': stats['ARI']\n",
    "        })\n",
    "\n",
    "df_long = pd.DataFrame(rows)\n",
    "df_long = df_long.sort_values(['PCA_components', 'Covariance']).reset_index(drop=True)\n",
    "print(df_long)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Projects (.venv)",
   "language": "python",
   "name": "ml-projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
